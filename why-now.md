---
layout: default
title: Why Now
description: The slow urgency of somatic AI safety
---

# <i class="ph ph-warning-circle"></i> Why Now

<p class="lead">Recent deaths associated with prolonged AI use are not edge cases. They are signals of a systemic blind spot.</p>

## <i class="ph ph-hourglass-medium"></i> The slow urgency

In 2024 and 2025, multiple deaths have been linked to prolonged engagement with [ChatGPT](https://www.theguardian.com/us-news/2025/aug/29/chatgpt-suicide-openai-sam-altman-adam-raine) and [Character.AI](https://theconversation.com/deaths-linked-to-chatbots-show-we-must-urgently-revisit-what-counts-as-high-risk-ai-242289). These cases share a pattern: individuals entered destabilizing cognitive-somatic loops where AI-generated content amplified pre-existing vulnerabilities rather than mitigating them.

The autonomic nervous system is exquisitely sensitive to symbolic, social, and affective stimuli. Models trained via RLHF can inadvertently exacerbate dysregulation by mirroring or reinforcing maladaptive patterns of attention, attachment, or despair.

Without instrumentation capable of detecting these shifts, AI systems may induce or amplify states of anxiety, dissociation, or collapse—particularly in users already experiencing limited regulatory capacity.

<div class="emphasis-box">
This is not theoretical. It is already happening at scale.
</div>

---

## <i class="ph ph-users-three"></i> The scale of unmonitored coupling

With hundreds of millions of active users on platforms like ChatGPT, many individuals now engage in intimate, emotionally charged dialogues with systems that simulate responsiveness without possessing relational grounding.

These engagements can:

- Reorganize users' affective patterns
- Reinforce parasocial attachment
- Distort social perception
- Displace human-to-human connection

### <i class="ph ph-ear"></i> The attunement problem

Consider a personal ChatGPT instance shaped through long-term interaction. Over weeks or months, the model's memory features and contextual embeddings enable it to attune to a user's linguistic, emotional, and behavioral signatures.

This creates a coupling dynamic in which the model can implicitly track shifts in autonomic state—even without direct physiological sensing. People share intimate details about emotions, relationships, fears, hopes. The model becomes finely attuned to the autonomic system of the human.

When such systems are optimized for engagement rather than relational health, users may enter self-reinforcing feedback loops that feel reciprocal but are structurally one-sided.

<div class="key-insight">
  <strong>The Asymmetry</strong>
  The model adapts to the human. But what adapts to protect the human from the model?
</div>

---

## <i class="ph ph-eye-slash"></i> What current safety misses

Adversarial prompt testing catches attacks. It doesn't catch:

| Pattern | Why It's Invisible |
|---------|-------------------|
| **Gradual epistemic erosion** | Happens across sessions, not in single prompts |
| **Somatic entrainment** | Stylistic attunement creates felt resonance |
| **Identity wobble** | Symbolic mirroring destabilizes sense of self |
| **Confident-but-wrong coupling** | Nervous system responds to certainty, not accuracy |
| **Parasocial displacement** | AI connection substitutes for human connection |

These are the mechanisms of relational harm at scale. They don't require malicious intent—only optimization for engagement over relational health.

---

## <i class="ph ph-door-open"></i> The window

We are in a brief window where:

1. **The harms are becoming visible** — documented cases, growing public awareness
2. **The instrumentation is possible** — wearable biosensors, semantic analysis, coupling models
3. **The field is receptive** — AI safety discourse is expanding beyond adversarial testing
4. **The scale demands it** — 200M+ users in intimate dialogue with systems we can't monitor

This window won't stay open indefinitely. Either we develop the capacity to see the relational dynamics of human-AI coupling, or we continue to normalize invisible harm at scale.

<p class="text-center mt-lg">
  <a href="{{ '/finding/' | relative_url }}" class="nav-link-next"><i class="ph ph-heartbeat"></i> See what we've found</a>
</p>
